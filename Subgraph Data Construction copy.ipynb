{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "670ba213-2a5c-424b-81ac-6b5f1e007b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Set, Dict\n",
    "from collections import defaultdict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b59253a-e860-4cb7-8e98-75791fa70a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "module_path = \"dsl.py\"\n",
    "spec = importlib.util.spec_from_file_location(\"function_module\", module_path)\n",
    "module = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57040c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import networkx as nx\n",
    "import ast\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Set, Dict, Tuple\n",
    "from itertools import combinations\n",
    "import networkx as nx\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Operation:\n",
    "    \"\"\"Represents an incremental operation in the function composition\"\"\"\n",
    "    input_expr: str\n",
    "    output_expr: str\n",
    "    function_str: str\n",
    "    depth: int\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.input_expr} -> {self.output_expr}\"\n",
    "\n",
    "class FunctionDecomposer:\n",
    "    def __init__(self, module_content: str):\n",
    "        self.operations: Set[Operation] = set()\n",
    "        self.variable_map: Dict[str, str] = {}\n",
    "        self.counter = 0\n",
    "        self.function_names = self._extract_function_names(module_content)\n",
    "    \n",
    "    def _extract_function_names(self, module_content: str) -> Set[str]:\n",
    "        \"\"\"Extract all function names defined in the module\"\"\"\n",
    "        tree = ast.parse(module_content)\n",
    "        return {node.name for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)}\n",
    "    \n",
    "    def get_fresh_variable(self) -> str:\n",
    "        \"\"\"Generate a fresh variable name\"\"\"\n",
    "        self.counter += 1\n",
    "        return f\"temp_{self.counter}\"\n",
    "    \n",
    "    def is_function_ref(self, name: str) -> bool:\n",
    "        \"\"\"Check if a name refers to a function defined in the module\"\"\"\n",
    "        return name in self.function_names\n",
    "    \n",
    "    def extract_operations(self, expr_str: str) -> List[Operation]:\n",
    "        \"\"\"Extract all incremental operations from a function expression\"\"\"\n",
    "        tree = ast.parse(expr_str).body[0].value\n",
    "        self.operations.clear()\n",
    "        self.variable_map.clear()\n",
    "        self.counter = 0\n",
    "        self._process_node(tree, \"I\", 0)\n",
    "        return sorted(self.operations, key=lambda x: (x.depth, x.output_expr))\n",
    "    \n",
    "    def _process_node(self, node: ast.AST, input_var: str, depth: int) -> Tuple[str, bool]:\n",
    "        \"\"\"\n",
    "        Process an AST node and extract operations.\n",
    "        Returns (expression_string, is_function_reference)\n",
    "        \"\"\"\n",
    "        if isinstance(node, ast.Name):\n",
    "            is_func = self.is_function_ref(node.id)\n",
    "            return node.id, is_func\n",
    "        \n",
    "        if isinstance(node, ast.Call):\n",
    "            func_name, _ = self._process_node(node.func, input_var, depth)\n",
    "            \n",
    "            # Process arguments\n",
    "            processed_args = []\n",
    "            for arg in node.args:\n",
    "                arg_expr, is_func_ref = self._process_node(arg, input_var, depth + 1)\n",
    "                \n",
    "                # Only create variables for non-function, non-constant values\n",
    "                if not (is_func_ref or arg_expr.isupper() or arg_expr == \"I\"):\n",
    "                    var_name = self.get_fresh_variable()\n",
    "                    self.variable_map[arg_expr] = var_name\n",
    "                    # Create operation for the intermediate result\n",
    "                    self.operations.add(Operation(\n",
    "                        input_expr=\"I\",\n",
    "                        output_expr=arg_expr,\n",
    "                        function_str=f\"lambda x: {arg_expr}\",\n",
    "                        depth=depth + 1\n",
    "                    ))\n",
    "                    processed_args.append(var_name)\n",
    "                else:\n",
    "                    processed_args.append(arg_expr)\n",
    "            \n",
    "            # Create the function call string\n",
    "            func_call = f\"{func_name}({', '.join(processed_args)})\"\n",
    "            \n",
    "            # Create operation for this function call\n",
    "            self.operations.add(Operation(\n",
    "                input_expr=\"I\",\n",
    "                output_expr=func_call,\n",
    "                function_str=f\"lambda x: {func_call}\",\n",
    "                depth=depth\n",
    "            ))\n",
    "            \n",
    "            return func_call, False  # Function call is not a function reference\n",
    "        \n",
    "        return input_var, False\n",
    "\n",
    "    def _remove_unnecessary_parentheses(self, expr: str) -> str:\n",
    "        \"\"\"Remove unnecessary parentheses from expression\"\"\"\n",
    "        stack = []\n",
    "        indices_to_remove = set()\n",
    "        last_open = -1\n",
    "        \n",
    "        # Find matching parentheses pairs\n",
    "        for i, c in enumerate(expr):\n",
    "            if c == '(':\n",
    "                stack.append(i)\n",
    "            elif c == ')' and stack:\n",
    "                start = stack.pop()\n",
    "                # Check if these parentheses are unnecessary\n",
    "                inner = expr[start+1:i]\n",
    "                if not inner.strip():  # Empty\n",
    "                    indices_to_remove.add(start)\n",
    "                    indices_to_remove.add(i)\n",
    "                elif inner.count('(') == inner.count(')'):  # Balanced inner expression\n",
    "                    if not any(c in inner for c in ', '): # No commas inside\n",
    "                        # Check if inner contains only a simple expression\n",
    "                        if not any(op in inner for op in ['+', '-', '*', '/', ' ']):\n",
    "                            indices_to_remove.add(start)\n",
    "                            indices_to_remove.add(i)\n",
    "        \n",
    "        # Rebuild string without unnecessary parentheses\n",
    "        return ''.join(c for i, c in enumerate(expr) if i not in indices_to_remove)\n",
    "\n",
    "    def _substitute_variables(self, expr: str, substitutions: Dict[str, str], seen: Set[str] = None) -> str:\n",
    "        \"\"\"\n",
    "        Substitute variables in expression while avoiding circular dependencies.\n",
    "        Returns cleaned-up expression with all possible substitutions made.\n",
    "        \"\"\"\n",
    "        if seen is None:\n",
    "            seen = set()\n",
    "        \n",
    "        # Find all variables that need to be substituted\n",
    "        changes_made = True\n",
    "        while changes_made:\n",
    "            changes_made = False\n",
    "            for var, sub_expr in substitutions.items():\n",
    "                if var in expr and var not in seen:\n",
    "                    seen.add(var)\n",
    "                    # Recursively substitute in the replacement expression first\n",
    "                    sub_expr = self._substitute_variables(sub_expr, substitutions, seen)\n",
    "                    # Only add parentheses if the substituted expression contains operators\n",
    "                    needs_parens = any(op in sub_expr for op in ['+', '-', '*', '/', ' ']) and not (sub_expr.startswith('(') and sub_expr.endswith(')'))\n",
    "                    wrapped_expr = f\"({sub_expr})\" if needs_parens else sub_expr\n",
    "                    expr = expr.replace(var, wrapped_expr)\n",
    "                    changes_made = True\n",
    "                    \n",
    "        return self._remove_unnecessary_parentheses(expr)\n",
    "\n",
    "    def get_all_granularities(self) -> List[List[Operation]]:\n",
    "        \"\"\"\n",
    "        Generate all possible granularities of the solution by merging operations.\n",
    "        Returns a list of lists, where each inner list represents one possible granularity level\n",
    "        ordered from finest (original operations) to coarsest (fully merged).\n",
    "        \"\"\"\n",
    "        # Build dependency graph\n",
    "        G = nx.DiGraph()\n",
    "        var_to_op = {}\n",
    "        \n",
    "        # Add all operations as nodes\n",
    "        for op in self.operations:\n",
    "            G.add_node(op)\n",
    "            if op.output_expr in self.variable_map:\n",
    "                var_to_op[self.variable_map[op.output_expr]] = op\n",
    "        \n",
    "        # Add edges based on variable dependencies\n",
    "        for op in self.operations:\n",
    "            for var_name in self.variable_map.values():\n",
    "                if var_name in op.function_str:\n",
    "                    if var_name in var_to_op:\n",
    "                        G.add_edge(var_to_op[var_name], op)\n",
    "        \n",
    "        def merge_operations(ops_to_merge: Set[Operation]) -> Operation:\n",
    "            \"\"\"Merge a set of operations into a single operation\"\"\"\n",
    "            sorted_ops = list(nx.topological_sort(G.subgraph(ops_to_merge)))\n",
    "            \n",
    "            # Build complete substitutions map\n",
    "            substitutions = {}\n",
    "            for op in sorted_ops:\n",
    "                if op.output_expr in self.variable_map:\n",
    "                    var_name = self.variable_map[op.output_expr]\n",
    "                    substitutions[var_name] = op.output_expr\n",
    "            \n",
    "            # Get the final expression and substitute all variables\n",
    "            final_expr = sorted_ops[-1].output_expr\n",
    "            merged_expr = self._substitute_variables(final_expr, substitutions)\n",
    "            \n",
    "            return Operation(\n",
    "                input_expr=\"I\",\n",
    "                output_expr=merged_expr,\n",
    "                function_str=f\"lambda x: {merged_expr}\",\n",
    "                depth=min(op.depth for op in ops_to_merge)\n",
    "            )\n",
    "        \n",
    "        def merge_operations(ops_to_merge: Set[Operation]) -> Operation:\n",
    "            \"\"\"Merge a set of operations into a single operation\"\"\"\n",
    "            # Sort operations by dependency order\n",
    "            sorted_ops = list(nx.topological_sort(G.subgraph(ops_to_merge)))\n",
    "            \n",
    "            # Create merged function string by substituting variables\n",
    "            final_expr = sorted_ops[-1].output_expr\n",
    "            substitutions = {}\n",
    "            \n",
    "            # Build substitutions map\n",
    "            for op in sorted_ops[:-1]:\n",
    "                if op.output_expr in self.variable_map:\n",
    "                    var_name = self.variable_map[op.output_expr]\n",
    "                    substitutions[var_name] = op.output_expr\n",
    "            \n",
    "            # Apply substitutions from deepest to shallowest\n",
    "            merged_expr = final_expr\n",
    "            while any(var in merged_expr for var in substitutions):\n",
    "                for var, expr in substitutions.items():\n",
    "                    merged_expr = merged_expr.replace(var, f\"({expr})\")\n",
    "            \n",
    "            return Operation(\n",
    "                input_expr=\"I\",\n",
    "                output_expr=merged_expr,\n",
    "                function_str=f\"lambda x: {merged_expr}\",\n",
    "                depth=min(op.depth for op in ops_to_merge)\n",
    "            )\n",
    "        \n",
    "        def is_valid_merge(ops_to_merge: Set[Operation]) -> bool:\n",
    "            \"\"\"Check if a set of operations can be validly merged\"\"\"\n",
    "            # Check if subgraph is connected\n",
    "            subgraph = G.subgraph(ops_to_merge)\n",
    "            return nx.is_weakly_connected(subgraph)\n",
    "        \n",
    "        def get_valid_merges(n: int) -> List[Set[Operation]]:\n",
    "            \"\"\"Get all valid combinations of n operations that can be merged\"\"\"\n",
    "            valid_merges = []\n",
    "            for ops in combinations(self.operations, n):\n",
    "                ops_set = set(ops)\n",
    "                if is_valid_merge(ops_set):\n",
    "                    valid_merges.append(ops_set)\n",
    "            return valid_merges\n",
    "        \n",
    "        # Generate all possible granularities\n",
    "        all_granularities = []\n",
    "        \n",
    "        # Start with finest granularity (original operations)\n",
    "        finest = sorted(self.operations, key=lambda x: (x.depth, x.output_expr))\n",
    "        all_granularities.append(finest)\n",
    "        \n",
    "        # Generate coarser granularities by merging operations\n",
    "        for size in range(2, len(self.operations) + 1):\n",
    "            valid_merges = get_valid_merges(size)\n",
    "            if not valid_merges:\n",
    "                continue\n",
    "                \n",
    "            granularity = []\n",
    "            used_ops = set()\n",
    "            \n",
    "            # For each valid merge\n",
    "            for merge_group in valid_merges:\n",
    "                # Skip if any operation in this group has been used\n",
    "                if any(op in used_ops for op in merge_group):\n",
    "                    continue\n",
    "                    \n",
    "                # Merge the operations\n",
    "                merged_op = merge_operations(merge_group)\n",
    "                granularity.append(merged_op)\n",
    "                used_ops.update(merge_group)\n",
    "                \n",
    "            # Add remaining operations that weren't merged\n",
    "            remaining_ops = [op for op in self.operations if op not in used_ops]\n",
    "            granularity.extend(remaining_ops)\n",
    "            \n",
    "            # Sort operations at this granularity level\n",
    "            granularity.sort(key=lambda x: (x.depth, x.output_expr))\n",
    "            \n",
    "            # Add this granularity level if it's different from previous ones\n",
    "            if granularity and granularity not in all_granularities:\n",
    "                all_granularities.append(granularity)\n",
    "        \n",
    "        return all_granularities\n",
    "\n",
    "def generate_granular_problems(expr_str: str, module_content: str) -> Dict[str, Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Generate problems at all possible granularities.\n",
    "    Returns a dictionary mapping granularity level to a dictionary of problems.\n",
    "    \"\"\"\n",
    "    decomposer = FunctionDecomposer(module_content)\n",
    "    decomposer.extract_operations(expr_str)\n",
    "    \n",
    "    all_granularities = decomposer.get_all_granularities()\n",
    "    \n",
    "    problems = {}\n",
    "    for i, granularity in enumerate(all_granularities):\n",
    "        level_problems = {}\n",
    "        for j, op in enumerate(granularity):\n",
    "            problem_id = f\"gran_{i}_step_{j:03d}\"\n",
    "            level_problems[problem_id] = op.function_str\n",
    "        problems[f\"level_{i}\"] = level_problems\n",
    "    \n",
    "    return problems\n",
    "\n",
    "def generate_incremental_problems(expr_str: str, module_content: str) -> Dict[str, str]:\n",
    "    \"\"\"Generate incremental problems from a function expression.\"\"\"\n",
    "    decomposer = FunctionDecomposer(module_content)\n",
    "    operations = decomposer.extract_operations(expr_str)\n",
    "    \n",
    "    problems = {}\n",
    "    for i, op in enumerate(operations):\n",
    "        problem_id = f\"inc_{i:03d}\"\n",
    "        problems[problem_id] = op.function_str\n",
    "    \n",
    "    return problems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35b5c6a-cccc-4116-93fd-13908535490c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ed4c462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Set\n",
    "import ast\n",
    "\n",
    "@dataclass\n",
    "class Step:\n",
    "    expression: str\n",
    "    result_var: str\n",
    "    dependencies: Set[str] = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.dependencies is None:\n",
    "            self.dependencies = set()\n",
    "\n",
    "class Solution:\n",
    "    def __init__(self):\n",
    "        self.steps: List[Step] = []\n",
    "        self.temp_counter = 0\n",
    "        self.var_map: Dict[str, str] = {}\n",
    "        \n",
    "    def add_step(self, expr: str, dependencies: Set[str] = None) -> str:\n",
    "        if expr in self.var_map:\n",
    "            return self.var_map[expr]\n",
    "        result_var = f\"temp_{self.temp_counter}\"\n",
    "        self.temp_counter += 1\n",
    "        step = Step(expr, result_var, dependencies or set())\n",
    "        self.steps.append(step)\n",
    "        self.var_map[expr] = result_var\n",
    "        return result_var\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"\\n\".join(f\"step {i}: {step.result_var} = {step.expression}\" \n",
    "                        for i, step in enumerate(self.steps))\n",
    "\n",
    "    def reorder_steps(self):\n",
    "        \"\"\"Reorder steps based on dependencies\"\"\"\n",
    "        dependency_graph = {step.result_var: step.dependencies for step in self.steps}\n",
    "        visited = set()\n",
    "        ordered_steps = []\n",
    "\n",
    "        def visit(var):\n",
    "            if var in visited:\n",
    "                return\n",
    "            visited.add(var)\n",
    "            for dep in dependency_graph.get(var, []):\n",
    "                visit(dep)\n",
    "            step = next(s for s in self.steps if s.result_var == var)\n",
    "            ordered_steps.append(step)\n",
    "\n",
    "        for step in self.steps:\n",
    "            visit(step.result_var)\n",
    "\n",
    "        self.steps = ordered_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47057d08-6563-4df0-aaca-b1b35224ad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Set\n",
    "\n",
    "def get_expression_str(node: ast.AST) -> str:\n",
    "    \"\"\"Convert an AST node back to its string representation.\"\"\"\n",
    "    if isinstance(node, ast.Name):\n",
    "        return node.id\n",
    "    elif isinstance(node, ast.Call):\n",
    "        args = [get_expression_str(arg) for arg in node.args]\n",
    "        return f\"{node.func.id}({', '.join(args)})\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected node type: {type(node)}\")\n",
    "\n",
    "def collect_calls(node: ast.AST) -> List[ast.Call]:\n",
    "    \"\"\"Collect all Call nodes in order from innermost to outermost.\"\"\"\n",
    "    calls = []\n",
    "    \n",
    "    def visit(node):\n",
    "        if isinstance(node, ast.Call):\n",
    "            # First visit all arguments\n",
    "            for arg in node.args:\n",
    "                visit(arg)\n",
    "            # Then add this call\n",
    "            calls.append(node)\n",
    "        return node\n",
    "        \n",
    "    visit(node)\n",
    "    return calls\n",
    "\n",
    "def substitute_expressions(expr: str, expr_map: Dict[str, str]) -> str:\n",
    "    \"\"\"Repeatedly substitute expressions until no more substitutions can be made.\"\"\"\n",
    "    prev_expr = None\n",
    "    current_expr = expr\n",
    "    \n",
    "    while prev_expr != current_expr:\n",
    "        prev_expr = current_expr\n",
    "        # Sort expressions by length (longest first) to avoid partial replacements\n",
    "        for old_expr, var in sorted(expr_map.items(), key=lambda x: len(x[0]), reverse=True):\n",
    "            if old_expr in current_expr and old_expr != current_expr:\n",
    "                current_expr = current_expr.replace(old_expr, var)\n",
    "    \n",
    "    return current_expr\n",
    "\n",
    "def generate_solutions(expr: str) -> List[Solution]:\n",
    "    # Parse the expression\n",
    "    tree = ast.parse(expr, mode='eval')\n",
    "    \n",
    "    # Get all function calls from innermost to outermost\n",
    "    calls = collect_calls(tree.body)\n",
    "    \n",
    "    # Create solutions\n",
    "    solutions = []\n",
    "    \n",
    "    # Solution 0: Just the complete expression\n",
    "    solution = Solution()\n",
    "    solution.add_step(get_expression_str(tree.body))\n",
    "    solutions.append(solution)\n",
    "    \n",
    "    # Create increasingly granular solutions\n",
    "    for i in range(len(calls) - 1, -1, -1):\n",
    "        solution = Solution()\n",
    "        expr_map = {}\n",
    "        \n",
    "        # Process all calls from index i onwards\n",
    "        for call in calls[i:]:\n",
    "            # Convert the call to string form and substitute all known expressions\n",
    "            current_expr = get_expression_str(call)\n",
    "            current_expr = substitute_expressions(current_expr, expr_map)\n",
    "            \n",
    "            # Add this step and remember the mapping\n",
    "            temp_var = solution.add_step(current_expr)\n",
    "            expr_map[get_expression_str(call)] = temp_var\n",
    "            \n",
    "            # Update any previous steps that could use this new variable\n",
    "            for step in solution.steps[:-1]:  # Skip the step we just added\n",
    "                step.expression = substitute_expressions(step.expression, expr_map)\n",
    "        \n",
    "        if len(solution.steps) > 1:  # Only add if we've broken something down\n",
    "            solutions.append(solution)\n",
    "    \n",
    "    return solutions\n",
    "\n",
    "def print_all_solutions(expr: str):\n",
    "    solutions = generate_solutions(expr)\n",
    "    for i, solution in enumerate(solutions):\n",
    "        print(f\"\\nSolution {i} ({'Most' if i == len(solutions)-1 else 'Least' if i == 0 else 'More'} Granular):\")\n",
    "        print(solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c713c8d-34c9-4ffc-8a87-600b174a383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from typing import Dict, Any, List, Tuple\n",
    "import inspect\n",
    "import dsl\n",
    "\n",
    "def format_collection(collection, indent=0):\n",
    "    \"\"\"Format a collection (set, frozenset, tuple) with readable output\"\"\"\n",
    "    if len(collection) == 0:\n",
    "        return \"empty\"\n",
    "        \n",
    "    items = list(collection)\n",
    "    try:\n",
    "        items.sort()\n",
    "    except TypeError:\n",
    "        pass\n",
    "    \n",
    "    formatted_items = []\n",
    "    indent_str = \" \" * (indent + 2)\n",
    "    \n",
    "    for item in items:\n",
    "        \n",
    "        if isinstance(item, frozenset):\n",
    "            formatted_items.append(format_collection(item, indent + 2))\n",
    "        else:\n",
    "            formatted_items.append(str(item))\n",
    "            \n",
    "    items_str = f\",\\n{indent_str}\".join(formatted_items)\n",
    "    return \"{\\n\" + indent_str + items_str + \"\\n\" + (\" \" * indent) + \"}\"\n",
    "\n",
    "def format_result(result):\n",
    "    if isinstance(result, tuple):\n",
    "        if len(result) == 0:\n",
    "            return \"()\"\n",
    "        if isinstance(result[0], tuple):\n",
    "            return f\"Grid {len(result)}x{len(result[0])}\"\n",
    "        if len(result) == 2 and all(isinstance(x, int) for x in result):\n",
    "            return f\"Point/Vector {result}\"\n",
    "        return f\"Tuple {format_collection(result)}\"\n",
    "    elif isinstance(result, (set, frozenset)):\n",
    "        unique_elements = set(result)\n",
    "        size_str = f\"FrozenSet of size {len(unique_elements)}\"\n",
    "        elements_str = format_collection(unique_elements)\n",
    "        return f\"{size_str}\\nElements: {elements_str}\"\n",
    "    elif callable(result):\n",
    "        return f\"Function {result.__name__}\"\n",
    "    return str(result)\n",
    "\n",
    "def print_grid(grid):\n",
    "    if not isinstance(grid, tuple) or not grid:\n",
    "        print(grid)\n",
    "        return\n",
    "    \n",
    "    if not isinstance(grid[0], tuple):\n",
    "        print(grid)\n",
    "        return\n",
    "    \n",
    "    print(f\"Grid {len(grid)}x{len(grid[0])}:\")\n",
    "    for row in grid:\n",
    "        print(\" \".join(str(x) for x in row))\n",
    "    print()\n",
    "\n",
    "def format_input_value(value):\n",
    "    \"\"\"Format an input value for display\"\"\"\n",
    "    if isinstance(value, tuple) and value and isinstance(value[0], tuple):\n",
    "        return f\"Grid {len(value)}x{len(value[0])}\"\n",
    "    return format_result(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "167c5dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from typing import Dict, Any, List, Tuple, Set\n",
    "import inspect\n",
    "import dsl\n",
    "import re\n",
    "\n",
    "class StepEvaluator:\n",
    "    def __init__(self):\n",
    "        self.functions = {\n",
    "            name: func for name, func in inspect.getmembers(dsl, inspect.isfunction)\n",
    "            if not name.startswith('_')\n",
    "        }\n",
    "        self.constants = {\n",
    "            'NEG_ONE': -1, 'NEG_TWO': -2, 'ZERO': 0, 'ONE': 1, 'TWO': 2,\n",
    "            'THREE': 3, 'FOUR': 4, 'FIVE': 5, 'SIX': 6, 'SEVEN': 7,\n",
    "            'EIGHT': 8, 'NINE': 9, 'TEN': 10, 'DOWN': (1, 0), 'RIGHT': (0, 1),\n",
    "            'UP': (-1, 0), 'LEFT': (0, -1), 'ORIGIN': (0, 0),\n",
    "            'UNITY': (1, 1), 'NEG_UNITY': (-1, -1), 'UP_RIGHT': (-1, 1),\n",
    "            'DOWN_LEFT': (1, -1), 'ZERO_BY_TWO': (0, 2),\n",
    "            'TWO_BY_ZERO': (2, 0), 'TWO_BY_TWO': (2, 2),\n",
    "            'THREE_BY_THREE': (3, 3), 'T': True, 'F': False\n",
    "        }\n",
    "        self.temp_values: Dict[str, Any] = {}\n",
    "        self.current_step_inputs: Dict[str, Any] = {}\n",
    "        self.pending_steps: Dict[str, str] = {}\n",
    "        \n",
    "    def evaluate_name(self, node: ast.Name) -> Any:\n",
    "        if node.id in self.temp_values:\n",
    "            self.current_step_inputs[node.id] = self.temp_values[node.id]\n",
    "            return self.temp_values[node.id]\n",
    "        elif node.id == 'I':\n",
    "            self.current_step_inputs['I'] = self.input_grid\n",
    "            return self.input_grid\n",
    "        elif node.id in self.constants:\n",
    "            return self.constants[node.id]\n",
    "        elif node.id in self.functions:\n",
    "            return self.functions[node.id]\n",
    "        elif node.id in self.pending_steps:\n",
    "            # Evaluate pending step first\n",
    "            pending_expr = self.pending_steps[node.id]\n",
    "            result = self.evaluate_expression(pending_expr)\n",
    "            self.temp_values[node.id] = result\n",
    "            self.current_step_inputs[node.id] = result\n",
    "            return result\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown variable or function: {node.id}\")\n",
    "        \n",
    "    def evaluate_call(self, node: ast.Call) -> Any:\n",
    "        if isinstance(node.func, ast.Name):\n",
    "            func_name = node.func.id\n",
    "            if func_name not in self.functions:\n",
    "                raise ValueError(f\"Unknown function: {func_name}\")\n",
    "            func = self.functions[func_name]\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported function reference type: {type(node.func)}\")\n",
    "            \n",
    "        args = []\n",
    "        for arg in node.args:\n",
    "            if isinstance(arg, ast.Name):\n",
    "                args.append(self.evaluate_name(arg))\n",
    "            elif isinstance(arg, ast.Call):\n",
    "                args.append(self.evaluate_call(arg))\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported argument type: {type(arg)}\")\n",
    "                \n",
    "        return func(*args)\n",
    "    \n",
    "    def evaluate_expression(self, expr: str) -> Any:\n",
    "        \"\"\"Evaluate a single expression\"\"\"\n",
    "        tree = ast.parse(expr, mode='eval')\n",
    "        return self.evaluate_call(tree.body)\n",
    "    \n",
    "    def evaluate_step(self, step_expr: str, result_var: str) -> Tuple[Any, Dict[str, Any]]:\n",
    "        \"\"\"Evaluate a step and return both result and inputs used\"\"\"\n",
    "        self.current_step_inputs = {}\n",
    "        result = self.evaluate_expression(step_expr)\n",
    "        self.temp_values[result_var] = result\n",
    "        return result, dict(self.current_step_inputs)\n",
    "\n",
    "    def evaluate_solution(self, solution, input_grid) -> List[Tuple[str, str, Any, Dict[str, Any]]]:\n",
    "        \"\"\"Evaluate all steps in a solution\"\"\"\n",
    "        self.input_grid = input_grid\n",
    "        self.temp_values.clear()\n",
    "        self.pending_steps.clear()\n",
    "        \n",
    "        # First collect all steps\n",
    "        for step in solution.steps:\n",
    "            self.pending_steps[step.result_var] = step.expression\n",
    "            \n",
    "        step_results = []\n",
    "        # Then evaluate them in order\n",
    "        for step in solution.steps:\n",
    "            try:\n",
    "                result, inputs = self.evaluate_step(step.expression, step.result_var)\n",
    "                step_results.append((step.result_var, step.expression, result, inputs))\n",
    "            except Exception as e:\n",
    "                print(f\"Error evaluating step {step.result_var} = {step.expression}\")\n",
    "                print(f\"Current temp_values: {list(self.temp_values.keys())}\")\n",
    "                raise\n",
    "            \n",
    "        return step_results\n",
    "\n",
    "# [Rest of the code remains the same: format_collection, format_result, print_grid, etc.]\n",
    "\n",
    "def check_callable(r):\n",
    "    if isinstance(r, (list, tuple, set, frozenset)):\n",
    "        return all(check_callable(x) for x in r) and len(r) > 0 #empty set would read true\n",
    "    else:\n",
    "        return callable(r)\n",
    "\n",
    "def compute_used(function_steps, inputs, expr):\n",
    "    return {\n",
    "        func_var: func_expr \n",
    "        for func_var, (func_expr, _) in function_steps.items() \n",
    "        if func_var in inputs or exact_pattern_match(func_var, expr)\n",
    "    }\n",
    "\n",
    "def exact_pattern_match(pattern_to_find, text):\n",
    "    # Escape any special regex characters in the pattern\n",
    "    escaped_pattern = re.escape(pattern_to_find)\n",
    "    # Add word boundary at the end\n",
    "    regex_pattern = fr'{escaped_pattern}\\b'\n",
    "    \n",
    "    return re.search(regex_pattern, text)\n",
    "\n",
    "def merge_used(function_steps, var, expr, result, inputs):\n",
    "\n",
    "    final_expr = expr\n",
    "    final_var = var\n",
    "    final_result = result\n",
    "    final_inputs = inputs\n",
    "    used_in_step = compute_used(function_steps, inputs, expr)\n",
    "    # print(\"orig used\", used_in_step)\n",
    "    # print(used_in_step)\n",
    "    while used_in_step:\n",
    "        # print(\"in while\",final_expr)\n",
    "        # 3. Substitute expressions\n",
    "        new_expr = final_expr\n",
    "        new_inputs = dict(final_inputs)\n",
    "        # print(used_in_step, \"before\")\n",
    "        for func_var, func_expr in used_in_step.items():\n",
    "            # Replace function variable with its expression\n",
    "            new_expr = new_expr.replace(func_var, f\"({func_expr})\")\n",
    "            # Update inputs\n",
    "            new_inputs.update(function_steps[func_var][1])\n",
    "            new_inputs.pop(func_var, None)\n",
    "            # used_functions.add(func_var)\n",
    "        \n",
    "        used_in_step = compute_used(function_steps, new_inputs, new_expr)\n",
    "        \n",
    "        # print(used_in_step, \"after\", new_expr, new_inputs)\n",
    "        final_expr = new_expr\n",
    "        final_inputs = new_inputs\n",
    "\n",
    "    return (final_var, final_expr, final_result, final_inputs)\n",
    "    \n",
    "\n",
    "\n",
    "def merge_function_steps(step_results):\n",
    "    \"\"\"\n",
    "    Merge steps by repeatedly:\n",
    "    1. Finding steps that return callables\n",
    "    2. Finding steps that use those callables\n",
    "    3. Substituting expressions\n",
    "    4. Renaming variables\n",
    "    5. Repeating until no callables remain\n",
    "    6. Removing any unused function-producing steps\n",
    "    \"\"\"\n",
    "    current_steps = list(step_results)\n",
    "    # print(current_steps, \"curr here\")\n",
    "    function_steps = {\n",
    "        var: (expr, inputs) \n",
    "        for var, expr, result, inputs in current_steps \n",
    "        # if (callable(result) or (isinstance(result, (list, tuple, set, frozenset)) and all(callable(r) for r in result)))\n",
    "        if check_callable(result)\n",
    "    }\n",
    "\n",
    "    while True:\n",
    "        # 1. Find steps that return callables\n",
    "\n",
    "        function_steps = {\n",
    "        var: (expr, inputs) \n",
    "        for var, expr, result, inputs in current_steps \n",
    "        # if (callable(result) or (isinstance(result, (list, tuple, set, frozenset)) and all(callable(r) for r in result)))\n",
    "        if check_callable(result)\n",
    "        }\n",
    "\n",
    "        if not function_steps:\n",
    "            break\n",
    "                \n",
    "        # 2. Find steps that use those callables and perform substitution\n",
    "        new_steps = []\n",
    "        used_functions = set()\n",
    "        \n",
    "        for var, expr, result, inputs in current_steps:\n",
    "            # print(\"iter through current\")\n",
    "            # Skip function steps that will be merged\n",
    "            if var in function_steps:\n",
    "                continue\n",
    "            new_steps.append(merge_used(function_steps, var, expr, result, inputs))\n",
    "        \n",
    "        # If no changes were made, break\n",
    "        if len(new_steps) == len(current_steps):\n",
    "            break\n",
    "            \n",
    "        current_steps = new_steps\n",
    "    # Final cleanup: remove any remaining function-producing steps\n",
    "    final_steps = []\n",
    "    function_vars = {var for var, _, result, _ in current_steps if check_callable(result)}\n",
    "    used_vars = set()\n",
    "    \n",
    "    # Collect all variables that are still being used\n",
    "    for _, expr, _, inputs in current_steps:\n",
    "        for var in function_vars:\n",
    "            if var in expr or var in str(inputs):\n",
    "                used_vars.add(var)\n",
    "    \n",
    "    # Keep only non-function steps and function steps that are still used\n",
    "    final_steps = [\n",
    "        step for step in current_steps\n",
    "        if not check_callable(step[2]) or step[0] in used_vars\n",
    "    ]\n",
    "    \n",
    "    return final_steps\n",
    "\n",
    "def evaluate_all_solutions(solutions, input_grid):\n",
    "    \"\"\"Evaluate all solutions with complete cleanup\"\"\"\n",
    "    evaluator = StepEvaluator()\n",
    "    all_results = []\n",
    "    \n",
    "    for i, solution in enumerate(solutions):\n",
    "        print(f\"\\nSolution {i} ({'Most' if i == len(solutions)-1 else 'Least' if i == 0 else 'More'} Granular):\")\n",
    "        print(solution)\n",
    "        print(\"\\nIntermediate Results:\")\n",
    "        \n",
    "        try:\n",
    "            # Get original step results\n",
    "            step_results = evaluator.evaluate_solution(solution, input_grid)\n",
    "            \n",
    "            # Merge steps recursively and cleanup\n",
    "            merged_steps = merge_function_steps(step_results)\n",
    "            \n",
    "            # Print merged results\n",
    "            for var, expr, result, inputs in merged_steps:\n",
    "                if not check_callable(result):  # Only show non-function results\n",
    "                    print(f\"\\n{var} = {expr}\")\n",
    "                    if inputs:\n",
    "                        print(\"Inputs:\")\n",
    "                        for input_var, input_val in inputs.items():\n",
    "                            print(f\"  {input_var}: {format_input_value(input_val)}\")\n",
    "                    print(f\"Result type: {type(result).__name__}\")\n",
    "                    print(\"Value:\", end=\" \")\n",
    "                    if isinstance(result, tuple) and result and isinstance(result[0], tuple):\n",
    "                        print_grid(result)\n",
    "                    else:\n",
    "                        print(\"\\n\" + format_result(result))\n",
    "                    \n",
    "            all_results.append(merged_steps)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in solution {i}:\")\n",
    "            print(str(e))\n",
    "            print(\"Continuing with next solution...\")\n",
    "            continue\n",
    "    \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c689c77e-0503-45fe-888e-115a2ee47025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from typing import Dict\n",
    "\n",
    "def map_function_returns(file_path: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Parse a Python file and map each function name to its return expression.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the Python file to analyze\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping function names to their return expressions as strings\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        source = file.read()\n",
    "    \n",
    "    tree = ast.parse(source)\n",
    "    return_map = {}\n",
    "    \n",
    "    class ReturnVisitor(ast.NodeVisitor):\n",
    "        def visit_FunctionDef(self, node):\n",
    "            returns = []\n",
    "            \n",
    "            # Inner class to find return statements\n",
    "            class ReturnFinder(ast.NodeVisitor):\n",
    "                def visit_Return(self, return_node):\n",
    "                    if return_node.value:  # Ignore bare 'return' statements\n",
    "                        returns.append(ast.unparse(return_node.value))\n",
    "            \n",
    "            # Find all return statements in the function\n",
    "            ReturnFinder().visit(node)\n",
    "            \n",
    "            # Join multiple returns with ' | ' if they exist\n",
    "            if returns:\n",
    "                return_map[node.name] = ' | '.join(returns)\n",
    "            else:\n",
    "                return_map[node.name] = 'None'  # Functions without explicit returns\n",
    "    \n",
    "    ReturnVisitor().visit(tree)\n",
    "    return return_map\n",
    "\n",
    "def print_return_map(file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Print the function return mappings in a readable format.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the Python file to analyze\n",
    "    \"\"\"\n",
    "    return_map = map_function_returns(file_path)\n",
    "    max_name_length = max(len(name) for name in return_map.keys())\n",
    "    \n",
    "    print(\"\\nFunction Return Expressions:\")\n",
    "    print(\"-\" * (max_name_length + 30))\n",
    "    for func_name, return_expr in sorted(return_map.items()):\n",
    "        print(f\"{func_name:<{max_name_length}} -> {return_expr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e360788e-49f2-4037-a4aa-4ffe43b432f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def get_data(train=True):\n",
    "    path = f'arc_original/{\"training\" if train else \"evaluation\"}'\n",
    "    data = {}\n",
    "    for fn in os.listdir(path):\n",
    "        with open(f'{path}/{fn}') as f:\n",
    "            data[fn.rstrip('.json')] = json.load(f)\n",
    "    ast = lambda g: tuple(tuple(r) for r in g)\n",
    "    return {\n",
    "        'train': {k: [{\n",
    "            'input': ast(e['input']),\n",
    "            'output': ast(e['output']),\n",
    "        } for e in v['train']] for k, v in data.items()},\n",
    "        'test': {k: [{\n",
    "            'input': ast(e['input']),\n",
    "            'output': ast(e['output']),\n",
    "        } for e in v['test']] for k, v in data.items()}\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a21da2e0-0c35-4fe4-b191-56615b56ffed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "def process_function(func_name, map_dict):\n",
    "    \"\"\"Process a single function and generate solutions.\"\"\"\n",
    "    exp = map_dict[func_name]\n",
    "    return func_name, generate_solutions(exp)\n",
    "# takes each function function to subcompoenent. =============================================================\n",
    "def parallel_generate_solutions(map_dict, num_processes=None):\n",
    "    \"\"\"\n",
    "    Generate solutions in parallel using multiple processes.\n",
    "    \n",
    "    Args:\n",
    "        map_dict: Dictionary mapping function names to expressions\n",
    "        num_processes: Number of processes to use (defaults to CPU count)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary mapping function names to their solutions\n",
    "    \"\"\"\n",
    "    if num_processes is None:\n",
    "        num_processes = cpu_count()\n",
    "\n",
    "    # Create a partial function with the map_dict argument fixed\n",
    "    process_func = partial(process_function, map_dict=map_dict)\n",
    "    \n",
    "    # Create a process pool\n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        # Use imap_unordered for better performance when order doesn't matter\n",
    "        # Wrap with tqdm for progress tracking\n",
    "        results = list(tqdm(\n",
    "            pool.imap_unordered(process_func, map_dict.keys()),\n",
    "            total=len(map_dict),\n",
    "            desc=\"Generating solutions\"\n",
    "        ))\n",
    "    \n",
    "    # Convert results list back to dictionary\n",
    "    return dict(results)\n",
    "\n",
    "def single_generate_solutions(map_dict):\n",
    "    results = {}\n",
    "    \n",
    "    # Process each function sequentially with progress bar\n",
    "    for func_name in tqdm(map_dict.keys(), desc=\"Generating solutions\"):\n",
    "        func_result = process_function(func_name, map_dict)\n",
    "        results[func_result[0]] = func_result[1]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e69fce8-c86d-4fa3-8553-68bd53d25315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_collection(collection):\n",
    "    \"\"\"Format a collection (set, frozenset, tuple) with readable output\"\"\"\n",
    "    items = list(collection)\n",
    "    try:\n",
    "        items.sort()\n",
    "    except TypeError:\n",
    "        pass\n",
    "    \n",
    "    formatted_items = []\n",
    "    \n",
    "    for item in items:\n",
    "        \n",
    "        if isinstance(item, frozenset):\n",
    "            formatted_items.append(format_collection(item))\n",
    "        else:\n",
    "            formatted_items.append(str(item))\n",
    "            \n",
    "    items_str = \" \".join(formatted_items)\n",
    "    return items_str\n",
    "\n",
    "def process_inputs(inputs):\n",
    "    return [process_result(inputs[k]) for k in inputs]\n",
    "\n",
    "def process_outputs(outputs):\n",
    "    return [process_result(o) for o in outputs]\n",
    "    \n",
    "def convert_frozenset_to_set(obj):\n",
    "    \"\"\"\n",
    "    Recursively converts FrozenSets to Sets in a nested data structure.\n",
    "    First converts everything to lists, then rebuilds with sets.\n",
    "    \n",
    "    Args:\n",
    "        obj: Any Python object that might contain FrozenSets\n",
    "        \n",
    "    Returns:\n",
    "        The same structure with all FrozenSets converted to Sets\n",
    "    \"\"\"\n",
    "    # First pass: convert everything to lists\n",
    "    def to_lists(obj):\n",
    "        if isinstance(obj, (str, int, float, bool, type(None))):\n",
    "            return obj\n",
    "        elif isinstance(obj, (frozenset, set)):\n",
    "            return [to_lists(x) for x in obj]\n",
    "        elif isinstance(obj, (list, tuple)):\n",
    "            return [to_lists(x) for x in obj]\n",
    "        elif isinstance(obj, dict):\n",
    "            return {to_lists(k): to_lists(v) for k, v in obj.items()}\n",
    "        else:\n",
    "            return obj\n",
    "\n",
    "    # Second pass: convert lists back to sets where needed\n",
    "    def to_sets(obj):\n",
    "        if isinstance(obj, (str, int, float, bool, type(None))):\n",
    "            return obj\n",
    "        elif isinstance(obj, list):\n",
    "            # Convert all elements first\n",
    "            converted = [to_sets(x) for x in obj]\n",
    "            # If this was originally a set/frozenset, make it a set\n",
    "            if isinstance(obj, (set, frozenset)):\n",
    "                return set(converted)\n",
    "            return converted\n",
    "        elif isinstance(obj, dict):\n",
    "            return {to_sets(k): to_sets(v) for k, v in obj.items()}\n",
    "        else:\n",
    "            return obj\n",
    "\n",
    "    # Run both passes\n",
    "    return to_sets(to_lists(obj))\n",
    "def process_result(result):\n",
    "    if isinstance(result, (set, frozenset)):\n",
    "        return convert_frozenset_to_set(result)\n",
    "    elif callable(result):\n",
    "        return \"function\"\n",
    "    else:\n",
    "        return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68af59c1-733b-4692-ae3f-1952ada3c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second step ============================================================================================\n",
    "def process_solution(solution, name):\n",
    "    evaluator = StepEvaluator()\n",
    "    key = name.replace(\"solve_\", \"\")\n",
    "    orig_inputs = [ex['input'] for ex in data['train'][key]]\n",
    "\n",
    "    steps_all_inputs = []\n",
    "    for I in orig_inputs:\n",
    "        step_results = evaluator.evaluate_solution(solution, I)\n",
    "        \n",
    "        merged_steps = merge_function_steps(step_results)\n",
    "        # print(merged_steps)\n",
    "        for step in merged_steps:\n",
    "            if callable(step[2]):\n",
    "                print(name)\n",
    "                print(solution)\n",
    "                print(step)\n",
    "        steps_all_inputs.append(merged_steps)\n",
    "    subroutines = {}\n",
    "    # return steps_all_inputs\n",
    "    # print(len(steps_all_inputs[0][0]))\n",
    "    for i in range(len(steps_all_inputs[0])):\n",
    "        inputs = [process_inputs(merged[i][3]) for merged in steps_all_inputs]\n",
    "        outputs = [process_result(merged[i][2]) for merged in steps_all_inputs]\n",
    "        program = f\"{steps_all_inputs[0][i][0]} = {steps_all_inputs[0][i][1]}\"\n",
    "        subroutines[f\"subroutine_{i}\"] = {\"inputs\": inputs,\n",
    "                                          \"outputs\": outputs,\n",
    "                                          \"program\": program}\n",
    "    return {\"original_task_key\": key,\n",
    "            \"subroutines\": subroutines}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddfd122c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need arc original data, solvers.py, incremental_arc_dataset.json, dsl.py. ========================================\n",
    "\n",
    "data = get_data()\n",
    "import json\n",
    "map = map_function_returns(\"rewritten_solvers.py\")\n",
    "\n",
    "with open(\"incremental_arc_dataset.json\", 'r') as fp:\n",
    "    incremental = json.load(fp)\n",
    "\n",
    "with open(\"dsl.py\", \"r\") as f:\n",
    "    module_content = f.read()\n",
    "evaluator = StepEvaluator()\n",
    "\n",
    "#map_to_solutions = single_generate_solutions(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c17a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mutation_data(mutation_file):\n",
    "    '''\n",
    "    this is the function to get the mutation data. The format should be same as get_data()\n",
    "    '''\n",
    "    # Load mutation solutions\n",
    "    with open(mutation_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Convert function matching original get_data() format\n",
    "    ast = lambda g: tuple(tuple(r) for r in g)\n",
    "    \n",
    "    processed_data = {}\n",
    "    for task_id, task_data in data.items():\n",
    "        # Format like original ARC JSON structure\n",
    "        processed_data[task_id] = {\n",
    "            'train': task_data['training_examples'],\n",
    "            'test': task_data['test_examples']\n",
    "        }\n",
    "\n",
    "    # Now format exactly like get_data() return structure\n",
    "    return {\n",
    "        'train': {k: [{\n",
    "            'input': ast(e['input']),\n",
    "            'output': ast(e['output']),\n",
    "        } for e in v['train']] for k, v in processed_data.items()},\n",
    "        'test': {k: [{\n",
    "            'input': ast(e['input']),\n",
    "            'output': ast(e['output']),\n",
    "        } for e in v['test']] for k, v in processed_data.items()}\n",
    "    }\n",
    "\n",
    "# Usage:\n",
    "new_data = get_mutation_data(\"mutated_tasks_train_9600.json\")\n",
    "\n",
    "# Now you can use this data exactly as if it came from get_data()\n",
    "# It will have the same structure and tuple format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b12f60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_solver(mutation_file):\n",
    "    '''\n",
    "    this is the function to get solvers from mutation data. The format should be the same as solvers.py. Need transformation to rewritte_solvers.py\n",
    "    '''\n",
    "    # Load mutation solutions\n",
    "    with open(mutation_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    # Extract all solver functions\n",
    "    solvers = {}\n",
    "    for task_id, task_data in data.items():\n",
    "        # Get the program definition directly \n",
    "        program = task_data['program']\n",
    "        # Add to solvers dictionary\n",
    "        solvers[task_id] = program\n",
    "\n",
    "    return solvers\n",
    "\n",
    "# Usage:\n",
    "solvers = get_solver(\"mutated_tasks_train_9600.json\")\n",
    "with open(\"new_solvers.py\", 'w') as f:\n",
    "    for solver in solvers.values():\n",
    "        f.write(solver + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73336abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating solutions: 100%|██████████| 400/400 [07:05<00:00,  1.06s/it]  \n"
     ]
    }
   ],
   "source": [
    "map = map_function_returns(\"rewritten_solvers.py\")\n",
    "\n",
    "with open(\"dsl.py\", \"r\") as f:\n",
    "    module_content = f.read()\n",
    "evaluator = StepEvaluator()\n",
    "\n",
    "map_to_solutions = single_generate_solutions(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56077ae9-30c7-49f6-8bed-341ac002f469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [01:29<00:00,  4.45it/s] \n"
     ]
    }
   ],
   "source": [
    "all_solutions = []\n",
    "for name in tqdm(map_to_solutions):\n",
    "    if name in ['solve_a64e4611', 'solve_2dd70a9a']:\n",
    "        continue\n",
    "    solutions = map_to_solutions[name]\n",
    "    for solution in solutions:\n",
    "        processed = process_solution(solution, name)\n",
    "        if processed is not None:\n",
    "            all_solutions.append(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79da4d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original_task_key': '67a3c6ac',\n",
       " 'subroutines': {'subroutine_0': {'inputs': [[((6, 6, 6, 2),\n",
       "      (6, 1, 6, 2),\n",
       "      (7, 2, 7, 2),\n",
       "      (1, 7, 2, 2))],\n",
       "    [((7, 7, 7, 6, 6, 6, 2),\n",
       "      (6, 7, 1, 1, 7, 7, 1),\n",
       "      (7, 7, 2, 1, 2, 6, 6),\n",
       "      (2, 2, 7, 7, 7, 2, 2),\n",
       "      (7, 2, 7, 1, 2, 7, 2),\n",
       "      (6, 6, 6, 2, 2, 1, 1),\n",
       "      (6, 2, 6, 6, 6, 6, 6))],\n",
       "    [((1, 2, 7, 1, 1, 1),\n",
       "      (2, 1, 7, 7, 2, 6),\n",
       "      (2, 1, 2, 6, 2, 1),\n",
       "      (1, 2, 1, 7, 6, 2),\n",
       "      (2, 7, 1, 2, 7, 1),\n",
       "      (2, 1, 6, 2, 7, 7))]],\n",
       "   'outputs': [((2, 6, 6, 6), (2, 6, 1, 6), (2, 7, 2, 7), (2, 2, 7, 1)),\n",
       "    ((2, 6, 6, 6, 7, 7, 7),\n",
       "     (1, 7, 7, 1, 1, 7, 6),\n",
       "     (6, 6, 2, 1, 2, 7, 7),\n",
       "     (2, 2, 7, 7, 7, 2, 2),\n",
       "     (2, 7, 2, 1, 7, 2, 7),\n",
       "     (1, 1, 2, 2, 6, 6, 6),\n",
       "     (6, 6, 6, 6, 6, 2, 6)),\n",
       "    ((1, 1, 1, 7, 2, 1),\n",
       "     (6, 2, 7, 7, 1, 2),\n",
       "     (1, 2, 6, 2, 1, 2),\n",
       "     (2, 6, 7, 1, 2, 1),\n",
       "     (1, 7, 2, 1, 7, 2),\n",
       "     (7, 7, 2, 6, 1, 2))],\n",
       "   'program': 'temp_0 = vmirror(I)'}}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_solutions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd1372a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original_task_key': '694f12f3',\n",
       " 'subroutines': {'subroutine_0': {'inputs': [[((0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
       "      (0, 4, 4, 4, 4, 0, 0, 0, 0, 0),\n",
       "      (0, 4, 4, 4, 4, 0, 0, 0, 0, 0),\n",
       "      (0, 4, 4, 4, 4, 0, 0, 0, 0, 0),\n",
       "      (0, 4, 4, 4, 4, 0, 0, 0, 0, 0),\n",
       "      (0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
       "      (0, 0, 0, 4, 4, 4, 4, 4, 4, 0),\n",
       "      (0, 0, 0, 4, 4, 4, 4, 4, 4, 0),\n",
       "      (0, 0, 0, 4, 4, 4, 4, 4, 4, 0),\n",
       "      (0, 0, 0, 4, 4, 4, 4, 4, 4, 0))],\n",
       "    [((0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
       "      (0, 4, 4, 4, 4, 4, 0, 0, 0, 0),\n",
       "      (0, 4, 4, 4, 4, 4, 0, 0, 0, 0),\n",
       "      (0, 4, 4, 4, 4, 4, 0, 0, 0, 0),\n",
       "      (0, 4, 4, 4, 4, 4, 0, 0, 0, 0),\n",
       "      (0, 4, 4, 4, 4, 4, 0, 0, 0, 0),\n",
       "      (0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
       "      (0, 0, 0, 0, 0, 4, 4, 4, 4, 0),\n",
       "      (0, 0, 0, 0, 0, 4, 4, 4, 4, 0),\n",
       "      (0, 0, 0, 0, 0, 4, 4, 4, 4, 0))]],\n",
       "   'outputs': [[[[4, [3, 1]],\n",
       "      [4, [4, 2]],\n",
       "      [4, [3, 3]],\n",
       "      [4, [2, 1]],\n",
       "      [4, [3, 2]],\n",
       "      [4, [4, 1]],\n",
       "      [4, [3, 4]],\n",
       "      [4, [1, 1]],\n",
       "      [4, [4, 3]],\n",
       "      [4, [2, 2]],\n",
       "      [4, [1, 3]],\n",
       "      [4, [4, 4]],\n",
       "      [4, [1, 2]],\n",
       "      [4, [2, 3]],\n",
       "      [4, [1, 4]],\n",
       "      [4, [2, 4]]],\n",
       "     [[0, [5, 0]],\n",
       "      [0, [0, 7]],\n",
       "      [0, [1, 9]],\n",
       "      [0, [7, 9]],\n",
       "      [0, [8, 0]],\n",
       "      [0, [0, 2]],\n",
       "      [0, [3, 7]],\n",
       "      [0, [4, 5]],\n",
       "      [0, [0, 8]],\n",
       "      [0, [5, 1]],\n",
       "      [0, [0, 3]],\n",
       "      [0, [1, 5]],\n",
       "      [0, [8, 1]],\n",
       "      [0, [4, 0]],\n",
       "      [0, [0, 9]],\n",
       "      [0, [3, 8]],\n",
       "      [0, [2, 6]],\n",
       "      [0, [1, 0]],\n",
       "      [0, [1, 6]],\n",
       "      [0, [8, 2]],\n",
       "      [0, [0, 4]],\n",
       "      [0, [5, 6]],\n",
       "      [0, [7, 0]],\n",
       "      [0, [3, 9]],\n",
       "      [0, [2, 7]],\n",
       "      [0, [9, 9]],\n",
       "      [0, [4, 9]],\n",
       "      [0, [6, 9]],\n",
       "      [0, [0, 5]],\n",
       "      [0, [7, 1]],\n",
       "      [0, [0, 0]],\n",
       "      [0, [2, 8]],\n",
       "      [0, [5, 7]],\n",
       "      [0, [5, 2]],\n",
       "      [0, [7, 2]],\n",
       "      [0, [3, 5]],\n",
       "      [0, [4, 6]],\n",
       "      [0, [2, 9]],\n",
       "      [0, [3, 0]],\n",
       "      [0, [5, 8]],\n",
       "      [0, [0, 1]],\n",
       "      [0, [5, 3]],\n",
       "      [0, [9, 0]],\n",
       "      [0, [3, 6]],\n",
       "      [0, [4, 7]],\n",
       "      [0, [5, 9]],\n",
       "      [0, [6, 0]],\n",
       "      [0, [5, 4]],\n",
       "      [0, [9, 1]],\n",
       "      [0, [1, 7]],\n",
       "      [0, [8, 9]],\n",
       "      [0, [2, 5]],\n",
       "      [0, [6, 1]],\n",
       "      [0, [4, 8]],\n",
       "      [0, [9, 2]],\n",
       "      [0, [1, 8]],\n",
       "      [0, [0, 6]],\n",
       "      [0, [2, 0]],\n",
       "      [0, [5, 5]],\n",
       "      [0, [6, 2]]],\n",
       "     [[4, [6, 6]],\n",
       "      [4, [7, 5]],\n",
       "      [4, [9, 8]],\n",
       "      [4, [7, 7]],\n",
       "      [4, [8, 4]],\n",
       "      [4, [9, 3]],\n",
       "      [4, [6, 8]],\n",
       "      [4, [6, 7]],\n",
       "      [4, [7, 6]],\n",
       "      [4, [7, 8]],\n",
       "      [4, [8, 3]],\n",
       "      [4, [9, 6]],\n",
       "      [4, [8, 5]],\n",
       "      [4, [9, 4]],\n",
       "      [4, [7, 3]],\n",
       "      [4, [6, 4]],\n",
       "      [4, [8, 6]],\n",
       "      [4, [6, 3]],\n",
       "      [4, [9, 7]],\n",
       "      [4, [7, 4]],\n",
       "      [4, [9, 5]],\n",
       "      [4, [6, 5]],\n",
       "      [4, [8, 8]],\n",
       "      [4, [8, 7]]]],\n",
       "    [[[4, [7, 5]],\n",
       "      [4, [8, 5]],\n",
       "      [4, [9, 8]],\n",
       "      [4, [7, 7]],\n",
       "      [4, [9, 5]],\n",
       "      [4, [8, 6]],\n",
       "      [4, [9, 7]],\n",
       "      [4, [9, 6]],\n",
       "      [4, [7, 6]],\n",
       "      [4, [7, 8]],\n",
       "      [4, [8, 8]],\n",
       "      [4, [8, 7]]],\n",
       "     [[0, [5, 0]],\n",
       "      [0, [0, 7]],\n",
       "      [0, [1, 9]],\n",
       "      [0, [7, 3]],\n",
       "      [0, [7, 9]],\n",
       "      [0, [8, 0]],\n",
       "      [0, [0, 2]],\n",
       "      [0, [3, 7]],\n",
       "      [0, [6, 3]],\n",
       "      [0, [0, 8]],\n",
       "      [0, [7, 4]],\n",
       "      [0, [0, 3]],\n",
       "      [0, [6, 7]],\n",
       "      [0, [8, 1]],\n",
       "      [0, [4, 0]],\n",
       "      [0, [0, 9]],\n",
       "      [0, [3, 8]],\n",
       "      [0, [2, 6]],\n",
       "      [0, [1, 0]],\n",
       "      [0, [1, 6]],\n",
       "      [0, [6, 8]],\n",
       "      [0, [8, 2]],\n",
       "      [0, [0, 4]],\n",
       "      [0, [9, 3]],\n",
       "      [0, [7, 0]],\n",
       "      [0, [5, 6]],\n",
       "      [0, [3, 9]],\n",
       "      [0, [2, 7]],\n",
       "      [0, [9, 9]],\n",
       "      [0, [4, 9]],\n",
       "      [0, [6, 9]],\n",
       "      [0, [8, 3]],\n",
       "      [0, [0, 5]],\n",
       "      [0, [7, 1]],\n",
       "      [0, [0, 0]],\n",
       "      [0, [2, 8]],\n",
       "      [0, [9, 4]],\n",
       "      [0, [5, 7]],\n",
       "      [0, [6, 4]],\n",
       "      [0, [7, 2]],\n",
       "      [0, [4, 6]],\n",
       "      [0, [2, 9]],\n",
       "      [0, [3, 0]],\n",
       "      [0, [5, 8]],\n",
       "      [0, [6, 5]],\n",
       "      [0, [0, 1]],\n",
       "      [0, [9, 0]],\n",
       "      [0, [3, 6]],\n",
       "      [0, [4, 7]],\n",
       "      [0, [5, 9]],\n",
       "      [0, [6, 0]],\n",
       "      [0, [6, 6]],\n",
       "      [0, [9, 1]],\n",
       "      [0, [1, 7]],\n",
       "      [0, [8, 9]],\n",
       "      [0, [8, 4]],\n",
       "      [0, [6, 1]],\n",
       "      [0, [4, 8]],\n",
       "      [0, [9, 2]],\n",
       "      [0, [1, 8]],\n",
       "      [0, [0, 6]],\n",
       "      [0, [2, 0]],\n",
       "      [0, [6, 2]]],\n",
       "     [[4, [5, 4]],\n",
       "      [4, [3, 1]],\n",
       "      [4, [4, 2]],\n",
       "      [4, [3, 3]],\n",
       "      [4, [2, 5]],\n",
       "      [4, [2, 1]],\n",
       "      [4, [3, 2]],\n",
       "      [4, [4, 1]],\n",
       "      [4, [4, 3]],\n",
       "      [4, [3, 4]],\n",
       "      [4, [1, 1]],\n",
       "      [4, [2, 2]],\n",
       "      [4, [5, 5]],\n",
       "      [4, [1, 3]],\n",
       "      [4, [4, 4]],\n",
       "      [4, [1, 2]],\n",
       "      [4, [5, 2]],\n",
       "      [4, [3, 5]],\n",
       "      [4, [1, 4]],\n",
       "      [4, [2, 3]],\n",
       "      [4, [2, 4]],\n",
       "      [4, [4, 5]],\n",
       "      [4, [5, 1]],\n",
       "      [4, [5, 3]],\n",
       "      [4, [1, 5]]]]],\n",
       "   'program': 'temp_1 = objects(I, T, F, F)'},\n",
       "  'subroutine_1': {'inputs': [[[[[4, [3, 1]],\n",
       "       [4, [4, 2]],\n",
       "       [4, [3, 3]],\n",
       "       [4, [2, 1]],\n",
       "       [4, [3, 2]],\n",
       "       [4, [4, 1]],\n",
       "       [4, [3, 4]],\n",
       "       [4, [1, 1]],\n",
       "       [4, [4, 3]],\n",
       "       [4, [2, 2]],\n",
       "       [4, [1, 3]],\n",
       "       [4, [4, 4]],\n",
       "       [4, [1, 2]],\n",
       "       [4, [2, 3]],\n",
       "       [4, [1, 4]],\n",
       "       [4, [2, 4]]],\n",
       "      [[0, [5, 0]],\n",
       "       [0, [0, 7]],\n",
       "       [0, [1, 9]],\n",
       "       [0, [7, 9]],\n",
       "       [0, [8, 0]],\n",
       "       [0, [0, 2]],\n",
       "       [0, [3, 7]],\n",
       "       [0, [4, 5]],\n",
       "       [0, [0, 8]],\n",
       "       [0, [5, 1]],\n",
       "       [0, [0, 3]],\n",
       "       [0, [1, 5]],\n",
       "       [0, [8, 1]],\n",
       "       [0, [4, 0]],\n",
       "       [0, [0, 9]],\n",
       "       [0, [3, 8]],\n",
       "       [0, [2, 6]],\n",
       "       [0, [1, 0]],\n",
       "       [0, [1, 6]],\n",
       "       [0, [8, 2]],\n",
       "       [0, [0, 4]],\n",
       "       [0, [5, 6]],\n",
       "       [0, [7, 0]],\n",
       "       [0, [3, 9]],\n",
       "       [0, [2, 7]],\n",
       "       [0, [9, 9]],\n",
       "       [0, [4, 9]],\n",
       "       [0, [6, 9]],\n",
       "       [0, [0, 5]],\n",
       "       [0, [7, 1]],\n",
       "       [0, [0, 0]],\n",
       "       [0, [2, 8]],\n",
       "       [0, [5, 7]],\n",
       "       [0, [5, 2]],\n",
       "       [0, [7, 2]],\n",
       "       [0, [3, 5]],\n",
       "       [0, [4, 6]],\n",
       "       [0, [2, 9]],\n",
       "       [0, [3, 0]],\n",
       "       [0, [5, 8]],\n",
       "       [0, [0, 1]],\n",
       "       [0, [5, 3]],\n",
       "       [0, [9, 0]],\n",
       "       [0, [3, 6]],\n",
       "       [0, [4, 7]],\n",
       "       [0, [5, 9]],\n",
       "       [0, [6, 0]],\n",
       "       [0, [5, 4]],\n",
       "       [0, [9, 1]],\n",
       "       [0, [1, 7]],\n",
       "       [0, [8, 9]],\n",
       "       [0, [2, 5]],\n",
       "       [0, [6, 1]],\n",
       "       [0, [4, 8]],\n",
       "       [0, [9, 2]],\n",
       "       [0, [1, 8]],\n",
       "       [0, [0, 6]],\n",
       "       [0, [2, 0]],\n",
       "       [0, [5, 5]],\n",
       "       [0, [6, 2]]],\n",
       "      [[4, [6, 6]],\n",
       "       [4, [7, 5]],\n",
       "       [4, [9, 8]],\n",
       "       [4, [7, 7]],\n",
       "       [4, [8, 4]],\n",
       "       [4, [9, 3]],\n",
       "       [4, [6, 8]],\n",
       "       [4, [6, 7]],\n",
       "       [4, [7, 6]],\n",
       "       [4, [7, 8]],\n",
       "       [4, [8, 3]],\n",
       "       [4, [9, 6]],\n",
       "       [4, [8, 5]],\n",
       "       [4, [9, 4]],\n",
       "       [4, [7, 3]],\n",
       "       [4, [6, 4]],\n",
       "       [4, [8, 6]],\n",
       "       [4, [6, 3]],\n",
       "       [4, [9, 7]],\n",
       "       [4, [7, 4]],\n",
       "       [4, [9, 5]],\n",
       "       [4, [6, 5]],\n",
       "       [4, [8, 8]],\n",
       "       [4, [8, 7]]]]],\n",
       "    [[[[4, [7, 5]],\n",
       "       [4, [8, 5]],\n",
       "       [4, [9, 8]],\n",
       "       [4, [7, 7]],\n",
       "       [4, [9, 5]],\n",
       "       [4, [8, 6]],\n",
       "       [4, [9, 7]],\n",
       "       [4, [9, 6]],\n",
       "       [4, [7, 6]],\n",
       "       [4, [7, 8]],\n",
       "       [4, [8, 8]],\n",
       "       [4, [8, 7]]],\n",
       "      [[0, [5, 0]],\n",
       "       [0, [0, 7]],\n",
       "       [0, [1, 9]],\n",
       "       [0, [7, 3]],\n",
       "       [0, [7, 9]],\n",
       "       [0, [8, 0]],\n",
       "       [0, [0, 2]],\n",
       "       [0, [3, 7]],\n",
       "       [0, [6, 3]],\n",
       "       [0, [0, 8]],\n",
       "       [0, [7, 4]],\n",
       "       [0, [0, 3]],\n",
       "       [0, [6, 7]],\n",
       "       [0, [8, 1]],\n",
       "       [0, [4, 0]],\n",
       "       [0, [0, 9]],\n",
       "       [0, [3, 8]],\n",
       "       [0, [2, 6]],\n",
       "       [0, [1, 0]],\n",
       "       [0, [1, 6]],\n",
       "       [0, [6, 8]],\n",
       "       [0, [8, 2]],\n",
       "       [0, [0, 4]],\n",
       "       [0, [9, 3]],\n",
       "       [0, [7, 0]],\n",
       "       [0, [5, 6]],\n",
       "       [0, [3, 9]],\n",
       "       [0, [2, 7]],\n",
       "       [0, [9, 9]],\n",
       "       [0, [4, 9]],\n",
       "       [0, [6, 9]],\n",
       "       [0, [8, 3]],\n",
       "       [0, [0, 5]],\n",
       "       [0, [7, 1]],\n",
       "       [0, [0, 0]],\n",
       "       [0, [2, 8]],\n",
       "       [0, [9, 4]],\n",
       "       [0, [5, 7]],\n",
       "       [0, [6, 4]],\n",
       "       [0, [7, 2]],\n",
       "       [0, [4, 6]],\n",
       "       [0, [2, 9]],\n",
       "       [0, [3, 0]],\n",
       "       [0, [5, 8]],\n",
       "       [0, [6, 5]],\n",
       "       [0, [0, 1]],\n",
       "       [0, [9, 0]],\n",
       "       [0, [3, 6]],\n",
       "       [0, [4, 7]],\n",
       "       [0, [5, 9]],\n",
       "       [0, [6, 0]],\n",
       "       [0, [6, 6]],\n",
       "       [0, [9, 1]],\n",
       "       [0, [1, 7]],\n",
       "       [0, [8, 9]],\n",
       "       [0, [8, 4]],\n",
       "       [0, [6, 1]],\n",
       "       [0, [4, 8]],\n",
       "       [0, [9, 2]],\n",
       "       [0, [1, 8]],\n",
       "       [0, [0, 6]],\n",
       "       [0, [2, 0]],\n",
       "       [0, [6, 2]]],\n",
       "      [[4, [5, 4]],\n",
       "       [4, [3, 1]],\n",
       "       [4, [4, 2]],\n",
       "       [4, [3, 3]],\n",
       "       [4, [2, 5]],\n",
       "       [4, [2, 1]],\n",
       "       [4, [3, 2]],\n",
       "       [4, [4, 1]],\n",
       "       [4, [4, 3]],\n",
       "       [4, [3, 4]],\n",
       "       [4, [1, 1]],\n",
       "       [4, [2, 2]],\n",
       "       [4, [5, 5]],\n",
       "       [4, [1, 3]],\n",
       "       [4, [4, 4]],\n",
       "       [4, [1, 2]],\n",
       "       [4, [5, 2]],\n",
       "       [4, [3, 5]],\n",
       "       [4, [1, 4]],\n",
       "       [4, [2, 3]],\n",
       "       [4, [2, 4]],\n",
       "       [4, [4, 5]],\n",
       "       [4, [5, 1]],\n",
       "       [4, [5, 3]],\n",
       "       [4, [1, 5]]]]]],\n",
       "   'outputs': [[[[4, [3, 1]],\n",
       "      [4, [4, 2]],\n",
       "      [4, [3, 3]],\n",
       "      [4, [2, 1]],\n",
       "      [4, [3, 2]],\n",
       "      [4, [4, 1]],\n",
       "      [4, [3, 4]],\n",
       "      [4, [1, 1]],\n",
       "      [4, [4, 3]],\n",
       "      [4, [2, 2]],\n",
       "      [4, [1, 3]],\n",
       "      [4, [4, 4]],\n",
       "      [4, [1, 2]],\n",
       "      [4, [2, 3]],\n",
       "      [4, [1, 4]],\n",
       "      [4, [2, 4]]],\n",
       "     [[4, [6, 6]],\n",
       "      [4, [7, 5]],\n",
       "      [4, [9, 8]],\n",
       "      [4, [7, 7]],\n",
       "      [4, [8, 4]],\n",
       "      [4, [9, 3]],\n",
       "      [4, [6, 8]],\n",
       "      [4, [6, 7]],\n",
       "      [4, [7, 6]],\n",
       "      [4, [7, 8]],\n",
       "      [4, [8, 3]],\n",
       "      [4, [9, 6]],\n",
       "      [4, [8, 5]],\n",
       "      [4, [9, 4]],\n",
       "      [4, [7, 3]],\n",
       "      [4, [6, 4]],\n",
       "      [4, [8, 6]],\n",
       "      [4, [6, 3]],\n",
       "      [4, [9, 7]],\n",
       "      [4, [7, 4]],\n",
       "      [4, [9, 5]],\n",
       "      [4, [6, 5]],\n",
       "      [4, [8, 8]],\n",
       "      [4, [8, 7]]]],\n",
       "    [[[4, [7, 5]],\n",
       "      [4, [8, 5]],\n",
       "      [4, [9, 8]],\n",
       "      [4, [7, 7]],\n",
       "      [4, [9, 5]],\n",
       "      [4, [8, 6]],\n",
       "      [4, [9, 7]],\n",
       "      [4, [9, 6]],\n",
       "      [4, [7, 6]],\n",
       "      [4, [7, 8]],\n",
       "      [4, [8, 8]],\n",
       "      [4, [8, 7]]],\n",
       "     [[4, [5, 4]],\n",
       "      [4, [3, 1]],\n",
       "      [4, [4, 2]],\n",
       "      [4, [3, 3]],\n",
       "      [4, [2, 5]],\n",
       "      [4, [2, 1]],\n",
       "      [4, [3, 2]],\n",
       "      [4, [4, 1]],\n",
       "      [4, [4, 3]],\n",
       "      [4, [3, 4]],\n",
       "      [4, [1, 1]],\n",
       "      [4, [2, 2]],\n",
       "      [4, [5, 5]],\n",
       "      [4, [1, 3]],\n",
       "      [4, [4, 4]],\n",
       "      [4, [1, 2]],\n",
       "      [4, [5, 2]],\n",
       "      [4, [3, 5]],\n",
       "      [4, [1, 4]],\n",
       "      [4, [2, 3]],\n",
       "      [4, [2, 4]],\n",
       "      [4, [4, 5]],\n",
       "      [4, [5, 1]],\n",
       "      [4, [5, 3]],\n",
       "      [4, [1, 5]]]]],\n",
       "   'program': 'temp_2 = colorfilter(temp_1, FOUR)'},\n",
       "  'subroutine_2': {'inputs': [[[[[4, [3, 1]],\n",
       "       [4, [4, 2]],\n",
       "       [4, [3, 3]],\n",
       "       [4, [2, 1]],\n",
       "       [4, [3, 2]],\n",
       "       [4, [4, 1]],\n",
       "       [4, [3, 4]],\n",
       "       [4, [1, 1]],\n",
       "       [4, [4, 3]],\n",
       "       [4, [2, 2]],\n",
       "       [4, [1, 3]],\n",
       "       [4, [4, 4]],\n",
       "       [4, [1, 2]],\n",
       "       [4, [2, 3]],\n",
       "       [4, [1, 4]],\n",
       "       [4, [2, 4]]],\n",
       "      [[4, [6, 6]],\n",
       "       [4, [7, 5]],\n",
       "       [4, [9, 8]],\n",
       "       [4, [7, 7]],\n",
       "       [4, [8, 4]],\n",
       "       [4, [9, 3]],\n",
       "       [4, [6, 8]],\n",
       "       [4, [6, 7]],\n",
       "       [4, [7, 6]],\n",
       "       [4, [7, 8]],\n",
       "       [4, [8, 3]],\n",
       "       [4, [9, 6]],\n",
       "       [4, [8, 5]],\n",
       "       [4, [9, 4]],\n",
       "       [4, [7, 3]],\n",
       "       [4, [6, 4]],\n",
       "       [4, [8, 6]],\n",
       "       [4, [6, 3]],\n",
       "       [4, [9, 7]],\n",
       "       [4, [7, 4]],\n",
       "       [4, [9, 5]],\n",
       "       [4, [6, 5]],\n",
       "       [4, [8, 8]],\n",
       "       [4, [8, 7]]]]],\n",
       "    [[[[4, [7, 5]],\n",
       "       [4, [8, 5]],\n",
       "       [4, [9, 8]],\n",
       "       [4, [7, 7]],\n",
       "       [4, [9, 5]],\n",
       "       [4, [8, 6]],\n",
       "       [4, [9, 7]],\n",
       "       [4, [9, 6]],\n",
       "       [4, [7, 6]],\n",
       "       [4, [7, 8]],\n",
       "       [4, [8, 8]],\n",
       "       [4, [8, 7]]],\n",
       "      [[4, [5, 4]],\n",
       "       [4, [3, 1]],\n",
       "       [4, [4, 2]],\n",
       "       [4, [3, 3]],\n",
       "       [4, [2, 5]],\n",
       "       [4, [2, 1]],\n",
       "       [4, [3, 2]],\n",
       "       [4, [4, 1]],\n",
       "       [4, [4, 3]],\n",
       "       [4, [3, 4]],\n",
       "       [4, [1, 1]],\n",
       "       [4, [2, 2]],\n",
       "       [4, [5, 5]],\n",
       "       [4, [1, 3]],\n",
       "       [4, [4, 4]],\n",
       "       [4, [1, 2]],\n",
       "       [4, [5, 2]],\n",
       "       [4, [3, 5]],\n",
       "       [4, [1, 4]],\n",
       "       [4, [2, 3]],\n",
       "       [4, [2, 4]],\n",
       "       [4, [4, 5]],\n",
       "       [4, [5, 1]],\n",
       "       [4, [5, 3]],\n",
       "       [4, [1, 5]]]]]],\n",
       "   'outputs': [[[4, [3, 1]],\n",
       "     [4, [4, 2]],\n",
       "     [4, [3, 3]],\n",
       "     [4, [2, 1]],\n",
       "     [4, [3, 2]],\n",
       "     [4, [4, 1]],\n",
       "     [4, [3, 4]],\n",
       "     [4, [1, 1]],\n",
       "     [4, [4, 3]],\n",
       "     [4, [2, 2]],\n",
       "     [4, [1, 3]],\n",
       "     [4, [4, 4]],\n",
       "     [4, [1, 2]],\n",
       "     [4, [2, 3]],\n",
       "     [4, [1, 4]],\n",
       "     [4, [2, 4]]],\n",
       "    [[4, [7, 5]],\n",
       "     [4, [8, 5]],\n",
       "     [4, [9, 8]],\n",
       "     [4, [7, 7]],\n",
       "     [4, [9, 5]],\n",
       "     [4, [8, 6]],\n",
       "     [4, [9, 7]],\n",
       "     [4, [9, 6]],\n",
       "     [4, [7, 6]],\n",
       "     [4, [7, 8]],\n",
       "     [4, [8, 8]],\n",
       "     [4, [8, 7]]]],\n",
       "   'program': 'temp_3 = argmin(temp_2, size)'},\n",
       "  'subroutine_3': {'inputs': [[[[4, [3, 1]],\n",
       "      [4, [4, 2]],\n",
       "      [4, [3, 3]],\n",
       "      [4, [2, 1]],\n",
       "      [4, [3, 2]],\n",
       "      [4, [4, 1]],\n",
       "      [4, [3, 4]],\n",
       "      [4, [1, 1]],\n",
       "      [4, [4, 3]],\n",
       "      [4, [2, 2]],\n",
       "      [4, [1, 3]],\n",
       "      [4, [4, 4]],\n",
       "      [4, [1, 2]],\n",
       "      [4, [2, 3]],\n",
       "      [4, [1, 4]],\n",
       "      [4, [2, 4]]]],\n",
       "    [[[4, [7, 5]],\n",
       "      [4, [8, 5]],\n",
       "      [4, [9, 8]],\n",
       "      [4, [7, 7]],\n",
       "      [4, [9, 5]],\n",
       "      [4, [8, 6]],\n",
       "      [4, [9, 7]],\n",
       "      [4, [9, 6]],\n",
       "      [4, [7, 6]],\n",
       "      [4, [7, 8]],\n",
       "      [4, [8, 8]],\n",
       "      [4, [8, 7]]]]],\n",
       "   'outputs': [[[2, 3], [3, 2], [3, 3], [2, 2]], [[8, 7], [8, 6]]],\n",
       "   'program': 'temp_4 = apply_func((compose(backdrop, inbox)), temp_3)'},\n",
       "  'subroutine_4': {'inputs': [[((0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
       "      (0, 4, 4, 4, 4, 0, 0, 0, 0, 0),\n",
       "      (0, 4, 4, 4, 4, 0, 0, 0, 0, 0),\n",
       "      (0, 4, 4, 4, 4, 0, 0, 0, 0, 0),\n",
       "      (0, 4, 4, 4, 4, 0, 0, 0, 0, 0),\n",
       "      (0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
       "      (0, 0, 0, 4, 4, 4, 4, 4, 4, 0),\n",
       "      (0, 0, 0, 4, 4, 4, 4, 4, 4, 0),\n",
       "      (0, 0, 0, 4, 4, 4, 4, 4, 4, 0),\n",
       "      (0, 0, 0, 4, 4, 4, 4, 4, 4, 0)),\n",
       "     [[2, 3], [3, 2], [3, 3], [2, 2]]],\n",
       "    [((0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
       "      (0, 4, 4, 4, 4, 4, 0, 0, 0, 0),\n",
       "      (0, 4, 4, 4, 4, 4, 0, 0, 0, 0),\n",
       "      (0, 4, 4, 4, 4, 4, 0, 0, 0, 0),\n",
       "      (0, 4, 4, 4, 4, 4, 0, 0, 0, 0),\n",
       "      (0, 4, 4, 4, 4, 4, 0, 0, 0, 0),\n",
       "      (0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
       "      (0, 0, 0, 0, 0, 4, 4, 4, 4, 0),\n",
       "      (0, 0, 0, 0, 0, 4, 4, 4, 4, 0),\n",
       "      (0, 0, 0, 0, 0, 4, 4, 4, 4, 0)),\n",
       "     [[8, 7], [8, 6]]]],\n",
       "   'outputs': [((0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
       "     (0, 4, 4, 4, 4, 0, 0, 0, 0, 0),\n",
       "     (0, 4, 1, 1, 4, 0, 0, 0, 0, 0),\n",
       "     (0, 4, 1, 1, 4, 0, 0, 0, 0, 0),\n",
       "     (0, 4, 4, 4, 4, 0, 0, 0, 0, 0),\n",
       "     (0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
       "     (0, 0, 0, 4, 4, 4, 4, 4, 4, 0),\n",
       "     (0, 0, 0, 4, 4, 4, 4, 4, 4, 0),\n",
       "     (0, 0, 0, 4, 4, 4, 4, 4, 4, 0),\n",
       "     (0, 0, 0, 4, 4, 4, 4, 4, 4, 0)),\n",
       "    ((0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
       "     (0, 4, 4, 4, 4, 4, 0, 0, 0, 0),\n",
       "     (0, 4, 4, 4, 4, 4, 0, 0, 0, 0),\n",
       "     (0, 4, 4, 4, 4, 4, 0, 0, 0, 0),\n",
       "     (0, 4, 4, 4, 4, 4, 0, 0, 0, 0),\n",
       "     (0, 4, 4, 4, 4, 4, 0, 0, 0, 0),\n",
       "     (0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
       "     (0, 0, 0, 0, 0, 4, 4, 4, 4, 0),\n",
       "     (0, 0, 0, 0, 0, 4, 1, 1, 4, 0),\n",
       "     (0, 0, 0, 0, 0, 4, 4, 4, 4, 0))],\n",
       "   'program': 'temp_5 = fill(I, ONE, temp_4)'},\n",
       "  'subroutine_5': {'inputs': [[[[[4, [3, 1]],\n",
       "       [4, [4, 2]],\n",
       "       [4, [3, 3]],\n",
       "       [4, [2, 1]],\n",
       "       [4, [3, 2]],\n",
       "       [4, [4, 1]],\n",
       "       [4, [3, 4]],\n",
       "       [4, [1, 1]],\n",
       "       [4, [4, 3]],\n",
       "       [4, [2, 2]],\n",
       "       [4, [1, 3]],\n",
       "       [4, [4, 4]],\n",
       "       [4, [1, 2]],\n",
       "       [4, [2, 3]],\n",
       "       [4, [1, 4]],\n",
       "       [4, [2, 4]]],\n",
       "      [[4, [6, 6]],\n",
       "       [4, [7, 5]],\n",
       "       [4, [9, 8]],\n",
       "       [4, [7, 7]],\n",
       "       [4, [8, 4]],\n",
       "       [4, [9, 3]],\n",
       "       [4, [6, 8]],\n",
       "       [4, [6, 7]],\n",
       "       [4, [7, 6]],\n",
       "       [4, [7, 8]],\n",
       "       [4, [8, 3]],\n",
       "       [4, [9, 6]],\n",
       "       [4, [8, 5]],\n",
       "       [4, [9, 4]],\n",
       "       [4, [7, 3]],\n",
       "       [4, [6, 4]],\n",
       "       [4, [8, 6]],\n",
       "       [4, [6, 3]],\n",
       "       [4, [9, 7]],\n",
       "       [4, [7, 4]],\n",
       "       [4, [9, 5]],\n",
       "       [4, [6, 5]],\n",
       "       [4, [8, 8]],\n",
       "       [4, [8, 7]]]]],\n",
       "    [[[[4, [7, 5]],\n",
       "       [4, [8, 5]],\n",
       "       [4, [9, 8]],\n",
       "       [4, [7, 7]],\n",
       "       [4, [9, 5]],\n",
       "       [4, [8, 6]],\n",
       "       [4, [9, 7]],\n",
       "       [4, [9, 6]],\n",
       "       [4, [7, 6]],\n",
       "       [4, [7, 8]],\n",
       "       [4, [8, 8]],\n",
       "       [4, [8, 7]]],\n",
       "      [[4, [5, 4]],\n",
       "       [4, [3, 1]],\n",
       "       [4, [4, 2]],\n",
       "       [4, [3, 3]],\n",
       "       [4, [2, 5]],\n",
       "       [4, [2, 1]],\n",
       "       [4, [3, 2]],\n",
       "       [4, [4, 1]],\n",
       "       [4, [4, 3]],\n",
       "       [4, [3, 4]],\n",
       "       [4, [1, 1]],\n",
       "       [4, [2, 2]],\n",
       "       [4, [5, 5]],\n",
       "       [4, [1, 3]],\n",
       "       [4, [4, 4]],\n",
       "       [4, [1, 2]],\n",
       "       [4, [5, 2]],\n",
       "       [4, [3, 5]],\n",
       "       [4, [1, 4]],\n",
       "       [4, [2, 3]],\n",
       "       [4, [2, 4]],\n",
       "       [4, [4, 5]],\n",
       "       [4, [5, 1]],\n",
       "       [4, [5, 3]],\n",
       "       [4, [1, 5]]]]]],\n",
       "   'outputs': [[[4, [6, 6]],\n",
       "     [4, [7, 5]],\n",
       "     [4, [9, 8]],\n",
       "     [4, [7, 7]],\n",
       "     [4, [8, 4]],\n",
       "     [4, [9, 3]],\n",
       "     [4, [6, 8]],\n",
       "     [4, [6, 7]],\n",
       "     [4, [7, 6]],\n",
       "     [4, [7, 8]],\n",
       "     [4, [8, 3]],\n",
       "     [4, [9, 6]],\n",
       "     [4, [8, 5]],\n",
       "     [4, [9, 4]],\n",
       "     [4, [7, 3]],\n",
       "     [4, [6, 4]],\n",
       "     [4, [8, 6]],\n",
       "     [4, [6, 3]],\n",
       "     [4, [9, 7]],\n",
       "     [4, [7, 4]],\n",
       "     [4, [9, 5]],\n",
       "     [4, [6, 5]],\n",
       "     [4, [8, 8]],\n",
       "     [4, [8, 7]]],\n",
       "    [[4, [5, 4]],\n",
       "     [4, [3, 1]],\n",
       "     [4, [4, 2]],\n",
       "     [4, [3, 3]],\n",
       "     [4, [2, 5]],\n",
       "     [4, [2, 1]],\n",
       "     [4, [3, 2]],\n",
       "     [4, [4, 1]],\n",
       "     [4, [4, 3]],\n",
       "     [4, [3, 4]],\n",
       "     [4, [1, 1]],\n",
       "     [4, [2, 2]],\n",
       "     [4, [5, 5]],\n",
       "     [4, [1, 3]],\n",
       "     [4, [4, 4]],\n",
       "     [4, [1, 2]],\n",
       "     [4, [5, 2]],\n",
       "     [4, [3, 5]],\n",
       "     [4, [1, 4]],\n",
       "     [4, [2, 3]],\n",
       "     [4, [2, 4]],\n",
       "     [4, [4, 5]],\n",
       "     [4, [5, 1]],\n",
       "     [4, [5, 3]],\n",
       "     [4, [1, 5]]]],\n",
       "   'program': 'temp_6 = argmax(temp_2, size)'},\n",
       "  'subroutine_6': {'inputs': [[[[4, [6, 6]],\n",
       "      [4, [7, 5]],\n",
       "      [4, [9, 8]],\n",
       "      [4, [7, 7]],\n",
       "      [4, [8, 4]],\n",
       "      [4, [9, 3]],\n",
       "      [4, [6, 8]],\n",
       "      [4, [6, 7]],\n",
       "      [4, [7, 6]],\n",
       "      [4, [7, 8]],\n",
       "      [4, [8, 3]],\n",
       "      [4, [9, 6]],\n",
       "      [4, [8, 5]],\n",
       "      [4, [9, 4]],\n",
       "      [4, [7, 3]],\n",
       "      [4, [6, 4]],\n",
       "      [4, [8, 6]],\n",
       "      [4, [6, 3]],\n",
       "      [4, [9, 7]],\n",
       "      [4, [7, 4]],\n",
       "      [4, [9, 5]],\n",
       "      [4, [6, 5]],\n",
       "      [4, [8, 8]],\n",
       "      [4, [8, 7]]]],\n",
       "    [[[4, [5, 4]],\n",
       "      [4, [3, 1]],\n",
       "      [4, [4, 2]],\n",
       "      [4, [3, 3]],\n",
       "      [4, [2, 5]],\n",
       "      [4, [2, 1]],\n",
       "      [4, [3, 2]],\n",
       "      [4, [4, 1]],\n",
       "      [4, [4, 3]],\n",
       "      [4, [3, 4]],\n",
       "      [4, [1, 1]],\n",
       "      [4, [2, 2]],\n",
       "      [4, [5, 5]],\n",
       "      [4, [1, 3]],\n",
       "      [4, [4, 4]],\n",
       "      [4, [1, 2]],\n",
       "      [4, [5, 2]],\n",
       "      [4, [3, 5]],\n",
       "      [4, [1, 4]],\n",
       "      [4, [2, 3]],\n",
       "      [4, [2, 4]],\n",
       "      [4, [4, 5]],\n",
       "      [4, [5, 1]],\n",
       "      [4, [5, 3]],\n",
       "      [4, [1, 5]]]]],\n",
       "   'outputs': [[[7, 4],\n",
       "     [8, 4],\n",
       "     [7, 7],\n",
       "     [8, 7],\n",
       "     [7, 6],\n",
       "     [8, 6],\n",
       "     [7, 5],\n",
       "     [8, 5]],\n",
       "    [[4, 4], [2, 4], [3, 4], [4, 3], [4, 2], [2, 3], [3, 3], [2, 2], [3, 2]]],\n",
       "   'program': 'temp_7 = apply_func((compose(backdrop, inbox)), temp_6)'},\n",
       "  'subroutine_7': {'inputs': [[((0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
       "      (0, 4, 4, 4, 4, 0, 0, 0, 0, 0),\n",
       "      (0, 4, 1, 1, 4, 0, 0, 0, 0, 0),\n",
       "      (0, 4, 1, 1, 4, 0, 0, 0, 0, 0),\n",
       "      (0, 4, 4, 4, 4, 0, 0, 0, 0, 0),\n",
       "      (0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
       "      (0, 0, 0, 4, 4, 4, 4, 4, 4, 0),\n",
       "      (0, 0, 0, 4, 4, 4, 4, 4, 4, 0),\n",
       "      (0, 0, 0, 4, 4, 4, 4, 4, 4, 0),\n",
       "      (0, 0, 0, 4, 4, 4, 4, 4, 4, 0)),\n",
       "     [[7, 4], [8, 4], [7, 7], [8, 7], [7, 6], [8, 6], [7, 5], [8, 5]]],\n",
       "    [((0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
       "      (0, 4, 4, 4, 4, 4, 0, 0, 0, 0),\n",
       "      (0, 4, 4, 4, 4, 4, 0, 0, 0, 0),\n",
       "      (0, 4, 4, 4, 4, 4, 0, 0, 0, 0),\n",
       "      (0, 4, 4, 4, 4, 4, 0, 0, 0, 0),\n",
       "      (0, 4, 4, 4, 4, 4, 0, 0, 0, 0),\n",
       "      (0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
       "      (0, 0, 0, 0, 0, 4, 4, 4, 4, 0),\n",
       "      (0, 0, 0, 0, 0, 4, 1, 1, 4, 0),\n",
       "      (0, 0, 0, 0, 0, 4, 4, 4, 4, 0)),\n",
       "     [[4, 4],\n",
       "      [2, 4],\n",
       "      [3, 4],\n",
       "      [4, 3],\n",
       "      [4, 2],\n",
       "      [2, 3],\n",
       "      [3, 3],\n",
       "      [2, 2],\n",
       "      [3, 2]]]],\n",
       "   'outputs': [((0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
       "     (0, 4, 4, 4, 4, 0, 0, 0, 0, 0),\n",
       "     (0, 4, 1, 1, 4, 0, 0, 0, 0, 0),\n",
       "     (0, 4, 1, 1, 4, 0, 0, 0, 0, 0),\n",
       "     (0, 4, 4, 4, 4, 0, 0, 0, 0, 0),\n",
       "     (0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
       "     (0, 0, 0, 4, 4, 4, 4, 4, 4, 0),\n",
       "     (0, 0, 0, 4, 2, 2, 2, 2, 4, 0),\n",
       "     (0, 0, 0, 4, 2, 2, 2, 2, 4, 0),\n",
       "     (0, 0, 0, 4, 4, 4, 4, 4, 4, 0)),\n",
       "    ((0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
       "     (0, 4, 4, 4, 4, 4, 0, 0, 0, 0),\n",
       "     (0, 4, 2, 2, 2, 4, 0, 0, 0, 0),\n",
       "     (0, 4, 2, 2, 2, 4, 0, 0, 0, 0),\n",
       "     (0, 4, 2, 2, 2, 4, 0, 0, 0, 0),\n",
       "     (0, 4, 4, 4, 4, 4, 0, 0, 0, 0),\n",
       "     (0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
       "     (0, 0, 0, 0, 0, 4, 4, 4, 4, 0),\n",
       "     (0, 0, 0, 0, 0, 4, 1, 1, 4, 0),\n",
       "     (0, 0, 0, 0, 0, 4, 4, 4, 4, 0))],\n",
       "   'program': 'temp_8 = fill(temp_5, TWO, temp_7)'}}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_solutions[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8797201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13062"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffaad21-3e80-4f7a-af33-6dbcc618d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = ['solve_9d9215db', 'solve_150deff5', 'solve_b7249182']\n",
    "test_keys = [t.replace(\"solve_\", \"\") for t in tests]\n",
    "test_examples = [soln for soln in all_solutions if soln['original_task_key'] in test_keys]\n",
    "train_examples = [soln for soln in all_solutions if soln['original_task_key'] not in test_keys]\n",
    "decomposed = {\"train\": train_examples, 'test': test_examples}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16cd3782-1e79-4349-899b-fb715782166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_non_serializable(obj, path=\"\"):\n",
    "    \"\"\"\n",
    "    Recursively traverse an object and find all paths that contain non-JSON-serializable items.\n",
    "    Specifically looks for function objects that would cause TypeError.\n",
    "    \n",
    "    Args:\n",
    "        obj: The object to inspect\n",
    "        path: Current path in the object (used recursively)\n",
    "        \n",
    "    Returns:\n",
    "        list: List of paths (strings) where functions were found\n",
    "    \"\"\"\n",
    "    problems = []\n",
    "    \n",
    "    # Handle different types\n",
    "    if isinstance(obj, dict):\n",
    "        for key, value in obj.items():\n",
    "            new_path = f\"{path}.{key}\" if path else str(key)\n",
    "            if callable(value):\n",
    "                problems.append((new_path, type(value).__name__))\n",
    "            else:\n",
    "                problems.extend(find_non_serializable(value, new_path))\n",
    "                \n",
    "    elif isinstance(obj, (list, tuple, set)):\n",
    "        for i, item in enumerate(obj):\n",
    "            new_path = f\"{path}[{i}]\"\n",
    "            if callable(item):\n",
    "                problems.append((new_path, type(item).__name__))\n",
    "            else:\n",
    "                problems.extend(find_non_serializable(item, new_path))\n",
    "                \n",
    "    elif callable(obj):\n",
    "        problems.append((path, type(obj).__name__))\n",
    "        \n",
    "    return problems\n",
    "\n",
    "def debug_json_serialization(obj):\n",
    "    \"\"\"\n",
    "    Wrapper function that provides a friendly output of all non-serializable paths found.\n",
    "    \n",
    "    Args:\n",
    "        obj: The object to inspect\n",
    "        \n",
    "    Returns:\n",
    "        None: Prints the problems found\n",
    "    \"\"\"\n",
    "    problems = find_non_serializable(obj)\n",
    "    \n",
    "    if not problems:\n",
    "        print(\"No serialization problems found!\")\n",
    "        return\n",
    "        \n",
    "    print(\"Found the following non-serializable items:\")\n",
    "    for path, type_name in problems:\n",
    "        print(f\"• At path '{path}': Found {type_name}\")\n",
    "    return problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b886d8ff-dc6f-4431-8ac9-b9d03b419c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = debug_json_serialization(decomposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fc3684-b616-4a93-a38d-ecde9e294648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_default(obj):\n",
    "    if isinstance(obj, (set, frozenset)):\n",
    "        return list(obj)\n",
    "    raise TypeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979195d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the decomposed solutions to a JSON file\n",
    "with open(\"arc_decomposed.json\", 'w') as f:\n",
    "    json.dump(decomposed, f, default=set_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006ed49e-f102-4bd5-abe7-21a823b807d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"arc_decomposed.json\", 'r') as fp:\n",
    "    solns = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15247815-7666-432e-ad33-4594d6887b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tuples(list_of_lists):\n",
    "    return tuple(tuple(t) for t in list_of_lists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3640ab62-673c-4110-8e62-5b6cc5419b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_tuples(solns['train'][1000]['subroutines']['subroutine_0']['outputs'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d295d731-55b2-46b0-a70d-a5c6385963b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "charset = set()\n",
    "step = 0\n",
    "for example in solns['train']:\n",
    "    for subroutine_name in example['subroutines']:\n",
    "        charset.update(set(str(example['subroutines'][subroutine_name]['outputs'])))\n",
    "        if \"-\" in str(example['subroutines'][subroutine_name]['outputs']):\n",
    "            print(str(example['subroutines'][subroutine_name]['outputs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1ebeb3",
   "metadata": {},
   "source": [
    "### Middle Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb69e849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8427 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'f8b3ba0a_it0_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m solutions \u001b[38;5;241m=\u001b[39m map_to_solutions[name]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m solution \u001b[38;5;129;01min\u001b[39;00m solutions:\n\u001b[0;32m----> 7\u001b[0m     processed \u001b[38;5;241m=\u001b[39m process_solution(solution, name)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m processed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m         all_solutions\u001b[38;5;241m.\u001b[39mappend(processed)\n",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m, in \u001b[0;36mprocess_solution\u001b[0;34m(solution, name)\u001b[0m\n\u001b[1;32m      3\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m StepEvaluator()\n\u001b[1;32m      4\u001b[0m key \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolve_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m orig_inputs \u001b[38;5;241m=\u001b[39m [ex[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m ex \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m][key]]\n\u001b[1;32m      7\u001b[0m steps_all_inputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m I \u001b[38;5;129;01min\u001b[39;00m orig_inputs:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'f8b3ba0a_it0_0'"
     ]
    }
   ],
   "source": [
    "all_solutions = []\n",
    "for name in tqdm(map_to_solutions):\n",
    "    if name in ['solve_a64e4611', 'solve_2dd70a9a']:\n",
    "        continue\n",
    "    solutions = map_to_solutions[name]\n",
    "    for solution in solutions:\n",
    "        processed = process_solution(solution, name)\n",
    "        if processed is not None:\n",
    "            all_solutions.append(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df7be79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
